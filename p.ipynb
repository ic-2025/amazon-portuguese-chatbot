{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 00:30:11.188227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743478211.202721  226145 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743478211.206768  226145 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743478211.219035  226145 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743478211.219061  226145 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743478211.219062  226145 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743478211.219064  226145 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-01 00:30:11.224324: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1743478214.684785  226145 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('portuguese_chatbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_26                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_27                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">189,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_15 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m47,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_26                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m788,480\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_27                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m370\u001b[0m)        │       \u001b[38;5;34m189,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,605,172</span> (9.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,605,172\u001b[0m (9.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,602,866</span> (9.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,602,866\u001b[0m (9.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/home/prinako/External/School/UFPA/ITEC_UFPA/24.4_SEMESTER/INTELIGENCIA_COMPUTACIONAL/T2/amazon-portuguese-chatbot/venv/lib/python3.11/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: input_layer\n",
      "Received: inputs=('Tensor(shape=(1, 100))', 'Tensor(shape=(1, 100))')\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: oi\n",
      "Chatbot: <OOV> para de quer de festa 10 da fica belos prato voce pobreza agosto recomendo 2 tipicas destes umido revitalizado hidrovia floresta periodos porto tem chegar\n",
      "\n",
      "User: conte-me sobre o folclore\n",
      "Chatbot: <OOV> por gostaria borracha 2000 maio tem festa catolica oncas mais origem fauna 1 dezembro marujada vivem saber saber oi virados arraial rios sopa campos boibumba internacional norte origem museu docas junho saber presepio 5 mae conhecida jari belemjulio ola belemjulio estacao guama sopa catolica tipicas 26c incriveis temperaturas lingua umido tapajos rua campos cabelos recomendo ouvir dia teve noite conhecida na destes fluvial conteme fundada significa campos cabanagem culinaria ola cultural reconhecida contra ou umido 10 norte imperdiveis lenda\n",
      "\n",
      "User: quais frutas tem na amazônia?\n",
      "Chatbot: <OOV> mil temperaturas cabanagem cabelos bom complexo em como sobre 26c cozido xingu aereo recomendo indigenas macacos eventos regiao antigo camarao 10 ou tapajos museu famoso clima equatorial culinaria botocorderosa\n",
      "\n",
      "User: quem é o curupira2?\n",
      "Chatbot: <OOV> bom 12011616 lenda folhas essencial fauna revitalizado antigo belem rua mas menos palacetes chegar abriga terminal boi reunindo vivem catirina complexo antas brasileiro ritmo tipicas 2o fascinante equatorial quem assado ouvir ocorre patrimonio foi aeroporto floresta construido ouvir bel mestre falar dezembro graopara centro cultural saber bel rua curupira paz forte floresta chuvoso recebendo capital docas passaros revitalizado namerica tocantins explosao ola comidas tocantins reunindo rios mil vatapa biodiversidade rios 3 sua 2o dias oncapintada chegar revitalizado em teve saber resistencia bom dia prato inclui quando paz aereo cabelos acontece 10 portuguesas mae quem 1 todo turismo barcos catolica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "model = load_model('portuguese_chatbot.h5')\n",
    "max_length = 100\n",
    "\n",
    "# Load tokenizer\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Normalize and clean text\n",
    "    text = unicodedata.normalize('NFKD', text.lower()).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def generate_response(input_text, temperature=0.7):\n",
    "    # Preprocess input\n",
    "    cleaned_input = preprocess_text(input_text)\n",
    "    input_seq = tokenizer.texts_to_sequences([cleaned_input])\n",
    "    input_padded = pad_sequences(input_seq, maxlen=max_length, padding='post')\n",
    "    \n",
    "    # Initialize response\n",
    "    response_seq = np.zeros((1, max_length))\n",
    "    response_seq[0, 0] = tokenizer.word_index['<OOV>']  # Start token\n",
    "    \n",
    "    for i in range(1, max_length):\n",
    "        # Predict next word\n",
    "        predictions = model.predict([input_padded, response_seq], verbose=0)[0][i-1]\n",
    "        \n",
    "        # Apply temperature for diversity\n",
    "        predictions = np.log(predictions) / temperature\n",
    "        exp_preds = np.exp(predictions)\n",
    "        predictions = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        # Sample from predictions\n",
    "        next_word_idx = np.random.choice(len(predictions), p=predictions)\n",
    "        response_seq[0, i] = next_word_idx\n",
    "        \n",
    "        # Stop if end token is predicted\n",
    "        if next_word_idx == 0:\n",
    "            break\n",
    "    \n",
    "    # Convert sequence to text\n",
    "    response_tokens = [tokenizer.index_word.get(idx, '') for idx in response_seq[0] if idx != 0]\n",
    "    return ' '.join(response_tokens)\n",
    "\n",
    "# Test the chatbot\n",
    "test_inputs = [\n",
    "    \"oi\",\n",
    "    \"conte-me sobre o folclore\",\n",
    "    \"quais frutas tem na amazônia?\",\n",
    "    \"quem é o curupira2?\"\n",
    "]\n",
    "\n",
    "for input_text in test_inputs:\n",
    "    response = generate_response(input_text)\n",
    "    print(f\"User: {input_text}\")\n",
    "    print(f\"Chatbot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: oi\n",
      "Chatbot: conte boa nazaré região paz dias açaí margens falar aeroporto origem estou lenda destacamse tradições castelo goeldi. chamada mandioca cezar explosão nazaré\n",
      "\n",
      "User: conte-me sobre o folclore\n",
      "Chatbot: mangal posso nazaré. teatro hoje melhor cabelos garças a o durante de tudo da palacetes tudo hoje essencial carnes.\n",
      "\n",
      "User: quais frutas tem na amazônia?\n",
      "Chatbot: km² 1 sopa mistura construção estado fluvial a o destacamse o a revitalizado que que conhecer morte você rodoviário falar\n",
      "\n",
      "User: quem é o curupira?\n",
      "Chatbot: portuguesas africanas região. história das docas. feita jambu você o internacional 3 catirina catirina seco aeroporto floresta. contar. ressurreição teatro código grãopará do belos nazaré?\n",
      "\n",
      "User: o que é Ver-o-Peso\n",
      "Chatbot: na clima nazaré km protege o 3 oferece foi nazaré. o conversar 1878 afroindígena novembro maior\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_response(input_text, temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate a response to the input text using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        input_text: User input string\n",
    "        temperature: Controls randomness of predictions (higher = more random)\n",
    "        \n",
    "    Returns:\n",
    "        Generated response string\n",
    "    \"\"\"\n",
    "    # Preprocess input\n",
    "    cleaned_input = preprocess_text(input_text)\n",
    "    input_seq = tokenizer.texts_to_sequences([cleaned_input])\n",
    "    input_padded = pad_sequences(input_seq, maxlen=max_length, padding='post')\n",
    "    \n",
    "    # Initialize response\n",
    "    response_seq = np.zeros((1, max_length))\n",
    "    response_seq[0, 0] = tokenizer.word_index['<OOV>']  # Start token\n",
    "    \n",
    "    for i in range(1, max_length):\n",
    "        # Predict next word\n",
    "        predictions = model.predict([input_padded, response_seq], verbose=0)[0][i-1]\n",
    "        \n",
    "        # Apply temperature for diversity\n",
    "        predictions = np.log(predictions) / temperature\n",
    "        exp_preds = np.exp(predictions)\n",
    "        predictions = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        # Sample from predictions\n",
    "        next_word_idx = np.random.choice(len(predictions), p=predictions)\n",
    "        response_seq[0, i] = next_word_idx\n",
    "        \n",
    "        # Stop if end token is predicted\n",
    "        if next_word_idx == 0:\n",
    "            break\n",
    "    \n",
    "    # Convert sequence to text\n",
    "    response_tokens = []\n",
    "    for idx in response_seq[0]:\n",
    "        if idx == 0:  # Skip padding\n",
    "            continue\n",
    "        word = tokenizer.index_word.get(idx, '')\n",
    "        if word == '<OOV>':  # Skip OOV tokens\n",
    "            continue\n",
    "        response_tokens.append(word)\n",
    "    \n",
    "    return ' '.join(response_tokens)\n",
    "\n",
    "# Test the chatbot\n",
    "test_inputs = [\n",
    "    \"oi\",\n",
    "    \"conte-me sobre o folclore\",\n",
    "    \"quais frutas tem na amazônia?\",\n",
    "    \"quem é o curupira?\",\n",
    "    \"o que é Ver-o-Peso\"\n",
    "]\n",
    "\n",
    "for input_text in test_inputs:\n",
    "    response = generate_response(input_text)\n",
    "    print(f\"User: {input_text}\")\n",
    "    print(f\"Chatbot: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
