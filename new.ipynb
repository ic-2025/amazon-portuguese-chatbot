{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import random\n",
    "\n",
    "def extract_text_from_pdfs(pdf_folder):\n",
    "    all_text = ''\n",
    "    for filename in os.listdir(pdf_folder):\n",
    "        if filename.endswith('.pdf'):\n",
    "            path = os.path.join(pdf_folder, filename)\n",
    "            with open(path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for page in reader.pages:\n",
    "                    all_text += page.extract_text() + '\\n'\n",
    "    return all_text\n",
    "\n",
    "pdf_folder = './pdfs'  # altere para o caminho real\n",
    "corpus_text = extract_text_from_pdfs(pdf_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# nltk.download('punkt',download_dir='./nltk_data', quiet=True)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # text = re.sub(r'\\n+', ' ', text)\n",
    "    # # MANTÉM . ! ? para detecção de fim de frase\n",
    "    # text = re.sub(r'[^a-záéíóúàãõç\\.\\!\\?\\s]', '', text)\n",
    "    # return text\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # mantém quebras de parágrafo\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r' +\\n', '\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "# corpus_text = \"Belém é a capital do Pará. É conhecida pelo Círio de Nazaré! Você já visitou?\"\n",
    "processed_text = preprocess_text(corpus_text)\n",
    "# clean_text = sent_tokenize(processed_text, language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">189,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m47,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m788,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m370\u001b[0m)        │       \u001b[38;5;34m189,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,605,172</span> (9.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,605,172\u001b[0m (9.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,602,866</span> (9.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,602,866\u001b[0m (9.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo carregado: <class 'keras.src.legacy.preprocessing.text.Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('portuguese_chatbot.h5')\n",
    "\n",
    "# Verify the model is loaded\n",
    "model.summary()\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Carrega o arquivo pickle\n",
    "with open('tokenizer.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "print(\"Conteúdo carregado:\", type(data))\n",
    "\n",
    "tokenizer = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prinako/External/School/UFPA/ITEC_UFPA/24.4_SEMESTER/INTELIGENCIA_COMPUTACIONAL/T2/amazon-portuguese-chatbot/venv/lib/python3.11/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: input_layer\n",
      "Received: inputs=('Tensor(shape=(1, 25))', 'Tensor(shape=(1, 25))')\n",
      "  warnings.warn(msg)\n",
      "I0000 00:00:1743513961.650349  804478 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: oi\n",
      "Chatbot: ajudar 40000 de internacional na pessoas lenda amazonicas do sabores unica hoje quais borboletas catirina conversar quente oi quer conhecer pato mandioca hidrovia cultura\n",
      "\n",
      "User: conte-me sobre o folclore\n",
      "Chatbot: 18351840 revolta 26c belem tacaca mandioca amazonia vermelhos oncas aqui outubro morte amazonia teve xingu milhao conta capital roteiro boi os 3 carnes equatorial\n",
      "\n",
      "User: quais frutas tem na amazônia?\n",
      "Chatbot: todo morte voce namerica culinaria amazonica prato portuguesas de vermelhos fundada cozido passaros quem francisco valdecans resistencia catirina fundada porto 26c liquido boibumba brasil\n",
      "\n",
      "User: quem é o curupira?\n",
      "Chatbot: explosao docas chamada borboletas das cidade reconhecida segundo 4 carnes tacaca 4 simbolo antecedencia tucupi m2 mangal comidas falar voos mortos principais cabelos m2\n",
      "\n",
      "User: o que é Ver-o-Peso\n",
      "Chatbot: regiao uma comidas chamada floresta construido considerada fascinante noite 12 cezar peixe 18791912 folclore chuvas destes verequete maior eventos veropeso hoje pavulagem vatapa camarao\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, RepeatVector\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess_text(text):\n",
    "    # Normalize and clean text\n",
    "    text = unicodedata.normalize('NFKD', text.lower()).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "max_length=25\n",
    "\n",
    "def generate_response(input_text, temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate a response to the input text using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        input_text: User input string\n",
    "        temperature: Controls randomness of predictions (higher = more random)\n",
    "        \n",
    "    Returns:\n",
    "        Generated response string\n",
    "    \"\"\"\n",
    "    # Preprocess input\n",
    "    cleaned_input = preprocess_text(input_text)\n",
    "    input_seq = tokenizer.texts_to_sequences([cleaned_input])\n",
    "    input_padded = pad_sequences(input_seq, maxlen=max_length, padding='post')\n",
    "    \n",
    "    # Initialize response\n",
    "    response_seq = np.zeros((1, max_length))\n",
    "    response_seq[0, 0] = tokenizer.word_index['<OOV>']  # Start token\n",
    "    \n",
    "    for i in range(1, max_length):\n",
    "        # Predict next word\n",
    "        predictions = model.predict([input_padded, response_seq], verbose=0)[0][i-1]\n",
    "        \n",
    "        # Apply temperature for diversity\n",
    "        predictions = np.log(predictions) / temperature\n",
    "        exp_preds = np.exp(predictions)\n",
    "        predictions = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        # Sample from predictions\n",
    "        next_word_idx = np.random.choice(len(predictions), p=predictions)\n",
    "        response_seq[0, i] = next_word_idx\n",
    "        \n",
    "        # Stop if end token is predicted\n",
    "        if next_word_idx == 0:\n",
    "            break\n",
    "    \n",
    "    # Convert sequence to text\n",
    "    response_tokens = []\n",
    "    for idx in response_seq[0]:\n",
    "        if idx == 0:  # Skip padding\n",
    "            continue\n",
    "        word = tokenizer.index_word.get(idx, '')\n",
    "        if word == '<OOV>':  # Skip OOV tokens\n",
    "            continue\n",
    "        response_tokens.append(word)\n",
    "    \n",
    "    return ' '.join(response_tokens)\n",
    "\n",
    "# Test the chatbot\n",
    "test_inputs = [\n",
    "    \"oi\",\n",
    "    \"conte-me sobre o folclore\",\n",
    "    \"quais frutas tem na amazônia?\",\n",
    "    \"quem é o curupira?\",\n",
    "    \"o que é Ver-o-Peso\"\n",
    "]\n",
    "\n",
    "for input_text in test_inputs:\n",
    "    response = generate_response(input_text)\n",
    "    print(f\"User: {input_text}\")\n",
    "    print(f\"Chatbot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: incriveis carnes 10 carimbo a ficar mercado garcas acontece goeldi aqui carne do fauna folclorica historico destacamse ecologico unica lingua teatro folclores culinaria folclore\n",
      "\n",
      "Chatbot: macacos 1625 e internacional neoclassico junho clima seco rios explosao pontos amazonia cabelos sopa clima biodiversidade famoso marujada\n",
      "\n",
      "Chatbot: melhor marujada visitar guama quem dos falar incriveis emilio chamada pobreza turisticas verequete jari destes quando folclore abriga boa cezar hidrovia incriveis tapajos domingo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_text = input(\"User: \")\n",
    "    response = generate_response(input_text)\n",
    "    print(f\"Chatbot: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
