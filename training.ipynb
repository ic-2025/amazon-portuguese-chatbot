{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d65adc-046f-43aa-94cd-abd19fff9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import random\n",
    "\n",
    "def extract_text_from_pdfs(pdf_folder):\n",
    "    all_text = ''\n",
    "    for filename in os.listdir(pdf_folder):\n",
    "        if filename.endswith('.pdf'):\n",
    "            path = os.path.join(pdf_folder, filename)\n",
    "            with open(path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for page in reader.pages:\n",
    "                    all_text += page.extract_text() + '\\n'\n",
    "    return all_text\n",
    "\n",
    "pdf_folder = './pdfs'  # altere para o caminho real\n",
    "corpus_text = extract_text_from_pdfs(pdf_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a46cab85-81b7-4076-99f7-7cf1d5fbe676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # text = re.sub(r'\\n+', ' ', text)\n",
    "    # # MANTÉM . ! ? para detecção de fim de frase\n",
    "    # text = re.sub(r'[^a-záéíóúàãõç\\.\\!\\?\\s]', '', text)\n",
    "    # return text\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # mantém quebras de parágrafo\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r' +\\n', '\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# corpus_text = \"Belém é a capital do Pará. É conhecida pelo Círio de Nazaré! Você já visitou?\"\n",
    "processed_text = preprocess_text(corpus_text)\n",
    "# clean_text = sent_tokenize(processed_text, language='portuguese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fdc7cd3-3d91-46be-8c4d-959752836c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraphs_into_sentences(text):\n",
    "    paragraphs = text.split('\\n')\n",
    "    sentences = []\n",
    "    for paragraph in paragraphs:\n",
    "        parts = re.split(r'(?<=[.!?])\\s+', paragraph.strip())\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if len(part) > 30:\n",
    "                sentences.append(part)\n",
    "    return sentences\n",
    "\n",
    "# === 4. Gerar perguntas/respostas ===\n",
    "def generate_qa_pairs(sentences):\n",
    "    qa_pairs = []\n",
    "    for i in range(1, len(sentences)):\n",
    "        prev = sentences[i-1]\n",
    "        curr = sentences[i]\n",
    "        question = f\"O que você pode me dizer sobre: '{prev[:60]}...'\"\n",
    "        answer = curr\n",
    "        qa_pairs.append((question, answer))\n",
    "    return qa_pairs\n",
    "\n",
    "def generate_qa_pairs_improved(sentences, min_words=6, max_chars=180):\n",
    "    question_templates = [\n",
    "        \"Você pode me explicar sobre \\\"{}\\\"?\",\n",
    "        \"O que é \\\"{}\\\"?\",\n",
    "        \"Fale sobre \\\"{}\\\".\",\n",
    "        \"O que você sabe sobre \\\"{}\\\"?\",\n",
    "        \"Qual a importância de \\\"{}\\\"?\",\n",
    "        \"Conte-me algo sobre \\\"{}\\\".\"\n",
    "    ]\n",
    "\n",
    "    qa_pairs = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        context = sentences[i].strip()\n",
    "        response = sentences[i+1].strip()\n",
    "\n",
    "        # Filtro: só usar como pergunta se tiver palavras suficientes\n",
    "        if len(context.split()) >= min_words and len(response.split()) >= min_words:\n",
    "            # Garante que termina com pontuação\n",
    "            context_clean = re.sub(r'\\s+', ' ', context)\n",
    "            context_clean = context_clean.strip()\n",
    "\n",
    "            # Se for muito longo, corta no último ponto final, interrogação ou exclamação antes do limite\n",
    "            if len(context_clean) > max_chars:\n",
    "                match = re.search(r'^(.{30,' + str(max_chars) + r'}[.!?])', context_clean)\n",
    "                if match:\n",
    "                    context_clean = match.group(1)\n",
    "\n",
    "            question_text = random.choice(question_templates).format(context_clean)\n",
    "            qa_pairs.append((question_text, response))\n",
    "\n",
    "    return qa_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a821239b-3fbe-44d8-9da2-74ba562f461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = split_paragraphs_into_sentences(processed_text)\n",
    "qa_pairs = generate_qa_pairs_improved(sentences)\n",
    "# qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "415ee3c4-8e55-413e-bd3e-ec9aecb316c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Separar perguntas e respostas\n",
    "perguntas = [q for q, _ in qa_pairs]\n",
    "respostas = [a for _, a in qa_pairs]\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(perguntas + respostas)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "# Sequenciar e padronizar\n",
    "max_len = 40  # pode ajustar\n",
    "X = tokenizer.texts_to_sequences(perguntas)\n",
    "y = tokenizer.texts_to_sequences(respostas)\n",
    "\n",
    "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
    "y = pad_sequences(y, maxlen=max_len, padding='post')\n",
    "\n",
    "# Ajustar formato do y para categorical_crossentropy\n",
    "y = np.expand_dims(y, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "861c86be-e967-41d5-8c71-b99cb9934d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">378,368</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2956</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">381,324</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m378,368\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m2956\u001b[0m)            │         \u001b[38;5;34m381,324\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">891,276</span> (3.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m891,276\u001b[0m (3.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">891,276</span> (3.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m891,276\u001b[0m (3.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "embedding_dim = 128\n",
    "\n",
    "input_seq = Input(shape=(max_len,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_seq)\n",
    "lstm = LSTM(128, return_sequences=True)(embedding)\n",
    "output = Dense(vocab_size, activation='softmax')(lstm)\n",
    "\n",
    "model = Model(input_seq, output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e5c7677-7230-4dbb-81d3-cf943a0c1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7485 - loss: 1.3467 - val_accuracy: 0.7135 - val_loss: 2.9999\n",
      "Epoch 2/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7405 - loss: 1.3740 - val_accuracy: 0.7115 - val_loss: 3.0325\n",
      "Epoch 3/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7438 - loss: 1.3515 - val_accuracy: 0.7067 - val_loss: 3.0446\n",
      "Epoch 4/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7475 - loss: 1.3283 - val_accuracy: 0.7067 - val_loss: 3.0562\n",
      "Epoch 5/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7519 - loss: 1.3006 - val_accuracy: 0.7118 - val_loss: 3.0609\n",
      "Epoch 6/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7547 - loss: 1.2852 - val_accuracy: 0.7045 - val_loss: 3.0782\n",
      "Epoch 7/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7550 - loss: 1.2768 - val_accuracy: 0.7062 - val_loss: 3.0922\n",
      "Epoch 8/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7565 - loss: 1.2562 - val_accuracy: 0.7025 - val_loss: 3.1072\n",
      "Epoch 9/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7598 - loss: 1.2412 - val_accuracy: 0.7059 - val_loss: 3.1269\n",
      "Epoch 10/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7678 - loss: 1.2011 - val_accuracy: 0.7045 - val_loss: 3.1351\n",
      "Epoch 11/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7627 - loss: 1.2204 - val_accuracy: 0.7053 - val_loss: 3.1440\n",
      "Epoch 12/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7665 - loss: 1.1991 - val_accuracy: 0.7073 - val_loss: 3.1491\n",
      "Epoch 13/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7713 - loss: 1.1672 - val_accuracy: 0.7022 - val_loss: 3.1678\n",
      "Epoch 14/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7730 - loss: 1.1621 - val_accuracy: 0.7048 - val_loss: 3.1769\n",
      "Epoch 15/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7729 - loss: 1.1644 - val_accuracy: 0.7006 - val_loss: 3.1957\n",
      "Epoch 16/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7769 - loss: 1.1361 - val_accuracy: 0.7011 - val_loss: 3.2083\n",
      "Epoch 17/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7840 - loss: 1.1083 - val_accuracy: 0.7008 - val_loss: 3.2202\n",
      "Epoch 18/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7795 - loss: 1.1224 - val_accuracy: 0.7042 - val_loss: 3.2290\n",
      "Epoch 19/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7890 - loss: 1.0782 - val_accuracy: 0.7034 - val_loss: 3.2377\n",
      "Epoch 20/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7900 - loss: 1.0663 - val_accuracy: 0.7008 - val_loss: 3.2515\n",
      "Epoch 21/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7907 - loss: 1.0660 - val_accuracy: 0.7000 - val_loss: 3.2738\n",
      "Epoch 22/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7974 - loss: 1.0401 - val_accuracy: 0.7014 - val_loss: 3.2653\n",
      "Epoch 23/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7967 - loss: 1.0353 - val_accuracy: 0.7006 - val_loss: 3.2931\n",
      "Epoch 24/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8025 - loss: 1.0116 - val_accuracy: 0.7006 - val_loss: 3.2908\n",
      "Epoch 25/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8076 - loss: 0.9823 - val_accuracy: 0.7034 - val_loss: 3.3061\n",
      "Epoch 26/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8089 - loss: 0.9820 - val_accuracy: 0.6994 - val_loss: 3.3170\n",
      "Epoch 27/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8125 - loss: 0.9694 - val_accuracy: 0.7011 - val_loss: 3.3219\n",
      "Epoch 28/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8154 - loss: 0.9558 - val_accuracy: 0.6975 - val_loss: 3.3503\n",
      "Epoch 29/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8194 - loss: 0.9326 - val_accuracy: 0.7000 - val_loss: 3.3545\n",
      "Epoch 30/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8193 - loss: 0.9240 - val_accuracy: 0.6963 - val_loss: 3.3742\n",
      "Epoch 31/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8224 - loss: 0.9156 - val_accuracy: 0.7003 - val_loss: 3.3800\n",
      "Epoch 32/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8257 - loss: 0.8925 - val_accuracy: 0.6972 - val_loss: 3.4034\n",
      "Epoch 33/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8261 - loss: 0.9008 - val_accuracy: 0.6947 - val_loss: 3.4168\n",
      "Epoch 34/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8256 - loss: 0.8934 - val_accuracy: 0.6969 - val_loss: 3.4258\n",
      "Epoch 35/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8282 - loss: 0.8806 - val_accuracy: 0.6966 - val_loss: 3.4221\n",
      "Epoch 36/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8313 - loss: 0.8650 - val_accuracy: 0.6966 - val_loss: 3.4327\n",
      "Epoch 37/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8361 - loss: 0.8496 - val_accuracy: 0.6963 - val_loss: 3.4609\n",
      "Epoch 38/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8384 - loss: 0.8350 - val_accuracy: 0.6944 - val_loss: 3.4728\n",
      "Epoch 39/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8426 - loss: 0.8214 - val_accuracy: 0.6978 - val_loss: 3.4771\n",
      "Epoch 40/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8428 - loss: 0.8184 - val_accuracy: 0.6986 - val_loss: 3.4917\n",
      "Epoch 41/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8476 - loss: 0.7995 - val_accuracy: 0.6949 - val_loss: 3.5125\n",
      "Epoch 42/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8467 - loss: 0.8017 - val_accuracy: 0.6966 - val_loss: 3.5234\n",
      "Epoch 43/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8492 - loss: 0.7888 - val_accuracy: 0.6944 - val_loss: 3.5341\n",
      "Epoch 44/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8504 - loss: 0.7844 - val_accuracy: 0.6992 - val_loss: 3.5381\n",
      "Epoch 45/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8553 - loss: 0.7706 - val_accuracy: 0.6955 - val_loss: 3.5458\n",
      "Epoch 46/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8592 - loss: 0.7520 - val_accuracy: 0.6961 - val_loss: 3.5575\n",
      "Epoch 47/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8575 - loss: 0.7574 - val_accuracy: 0.6927 - val_loss: 3.5731\n",
      "Epoch 48/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8596 - loss: 0.7430 - val_accuracy: 0.6944 - val_loss: 3.5866\n",
      "Epoch 49/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8613 - loss: 0.7325 - val_accuracy: 0.6930 - val_loss: 3.5982\n",
      "Epoch 50/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8610 - loss: 0.7348 - val_accuracy: 0.6983 - val_loss: 3.6002\n",
      "Epoch 51/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8668 - loss: 0.7162 - val_accuracy: 0.6947 - val_loss: 3.6221\n",
      "Epoch 52/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8683 - loss: 0.7032 - val_accuracy: 0.6941 - val_loss: 3.6228\n",
      "Epoch 53/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8697 - loss: 0.6943 - val_accuracy: 0.6899 - val_loss: 3.6442\n",
      "Epoch 54/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8728 - loss: 0.6854 - val_accuracy: 0.6952 - val_loss: 3.6498\n",
      "Epoch 55/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8720 - loss: 0.6798 - val_accuracy: 0.6944 - val_loss: 3.6560\n",
      "Epoch 56/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8741 - loss: 0.6710 - val_accuracy: 0.6941 - val_loss: 3.6786\n",
      "Epoch 57/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8768 - loss: 0.6650 - val_accuracy: 0.6919 - val_loss: 3.6890\n",
      "Epoch 58/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.6678 - val_accuracy: 0.6927 - val_loss: 3.7019\n",
      "Epoch 59/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8791 - loss: 0.6477 - val_accuracy: 0.6955 - val_loss: 3.7066\n",
      "Epoch 60/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8786 - loss: 0.6567 - val_accuracy: 0.6919 - val_loss: 3.7199\n",
      "Epoch 61/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8794 - loss: 0.6472 - val_accuracy: 0.6941 - val_loss: 3.7271\n",
      "Epoch 62/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8830 - loss: 0.6305 - val_accuracy: 0.6919 - val_loss: 3.7349\n",
      "Epoch 63/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8844 - loss: 0.6278 - val_accuracy: 0.6927 - val_loss: 3.7496\n",
      "Epoch 64/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8844 - loss: 0.6167 - val_accuracy: 0.6904 - val_loss: 3.7686\n",
      "Epoch 65/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8848 - loss: 0.6206 - val_accuracy: 0.6921 - val_loss: 3.7827\n",
      "Epoch 66/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8874 - loss: 0.6049 - val_accuracy: 0.6919 - val_loss: 3.7824\n",
      "Epoch 67/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8879 - loss: 0.6038 - val_accuracy: 0.6904 - val_loss: 3.7954\n",
      "Epoch 68/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8845 - loss: 0.6126 - val_accuracy: 0.6941 - val_loss: 3.8033\n",
      "Epoch 69/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8875 - loss: 0.6040 - val_accuracy: 0.6896 - val_loss: 3.8237\n",
      "Epoch 70/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8880 - loss: 0.5971 - val_accuracy: 0.6874 - val_loss: 3.8279\n",
      "Epoch 71/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8883 - loss: 0.5955 - val_accuracy: 0.6933 - val_loss: 3.8138\n",
      "Epoch 72/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8908 - loss: 0.5828 - val_accuracy: 0.6930 - val_loss: 3.8473\n",
      "Epoch 73/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8903 - loss: 0.5874 - val_accuracy: 0.6910 - val_loss: 3.8524\n",
      "Epoch 74/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8922 - loss: 0.5724 - val_accuracy: 0.6941 - val_loss: 3.8511\n",
      "Epoch 75/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8933 - loss: 0.5705 - val_accuracy: 0.6896 - val_loss: 3.8763\n",
      "Epoch 76/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8930 - loss: 0.5725 - val_accuracy: 0.6902 - val_loss: 3.8762\n",
      "Epoch 77/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8923 - loss: 0.5707 - val_accuracy: 0.6868 - val_loss: 3.8904\n",
      "Epoch 78/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8941 - loss: 0.5636 - val_accuracy: 0.6944 - val_loss: 3.9002\n",
      "Epoch 79/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8959 - loss: 0.5583 - val_accuracy: 0.6904 - val_loss: 3.9111\n",
      "Epoch 80/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8931 - loss: 0.5648 - val_accuracy: 0.6904 - val_loss: 3.9162\n",
      "Epoch 81/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8946 - loss: 0.5586 - val_accuracy: 0.6893 - val_loss: 3.9268\n",
      "Epoch 82/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8950 - loss: 0.5559 - val_accuracy: 0.6924 - val_loss: 3.9389\n",
      "Epoch 83/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8960 - loss: 0.5523 - val_accuracy: 0.6902 - val_loss: 3.9436\n",
      "Epoch 84/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8980 - loss: 0.5399 - val_accuracy: 0.6910 - val_loss: 3.9580\n",
      "Epoch 85/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8958 - loss: 0.5432 - val_accuracy: 0.6907 - val_loss: 3.9616\n",
      "Epoch 86/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8955 - loss: 0.5425 - val_accuracy: 0.6871 - val_loss: 3.9745\n",
      "Epoch 87/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8963 - loss: 0.5384 - val_accuracy: 0.6913 - val_loss: 3.9751\n",
      "Epoch 88/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8952 - loss: 0.5458 - val_accuracy: 0.6916 - val_loss: 3.9916\n",
      "Epoch 89/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8971 - loss: 0.5332 - val_accuracy: 0.6882 - val_loss: 3.9913\n",
      "Epoch 90/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8967 - loss: 0.5355 - val_accuracy: 0.6860 - val_loss: 4.0075\n",
      "Epoch 91/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8983 - loss: 0.5295 - val_accuracy: 0.6893 - val_loss: 4.0186\n",
      "Epoch 92/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8979 - loss: 0.5261 - val_accuracy: 0.6885 - val_loss: 4.0205\n",
      "Epoch 93/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8978 - loss: 0.5333 - val_accuracy: 0.6888 - val_loss: 4.0346\n",
      "Epoch 94/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9002 - loss: 0.5188 - val_accuracy: 0.6885 - val_loss: 4.0304\n",
      "Epoch 95/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8992 - loss: 0.5174 - val_accuracy: 0.6896 - val_loss: 4.0529\n",
      "Epoch 96/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8986 - loss: 0.5182 - val_accuracy: 0.6885 - val_loss: 4.0493\n",
      "Epoch 97/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8965 - loss: 0.5228 - val_accuracy: 0.6893 - val_loss: 4.0705\n",
      "Epoch 98/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8969 - loss: 0.5210 - val_accuracy: 0.6933 - val_loss: 4.0539\n",
      "Epoch 99/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8970 - loss: 0.5203 - val_accuracy: 0.6916 - val_loss: 4.0544\n",
      "Epoch 100/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8989 - loss: 0.5168 - val_accuracy: 0.6890 - val_loss: 4.0555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x211b7328e30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=16, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "359bf9d2-d33b-43a0-a545-fe09f062daa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "o de do 136 faculdades com com com\n"
     ]
    }
   ],
   "source": [
    "def responder(pergunta, max_len=40):\n",
    "    seq = tokenizer.texts_to_sequences([pergunta])\n",
    "    padded = pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "    pred = model.predict(padded)[0]\n",
    "    pred_ids = np.argmax(pred, axis=-1)\n",
    "\n",
    "    resposta = \" \".join([tokenizer.index_word.get(i, '') for i in pred_ids if i != 0])\n",
    "    return resposta.strip()\n",
    "\n",
    "# Exemplo:\n",
    "print(responder(\"O que é o Ver-o-Peso?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d45a98-db66-4c18-b50e-010c10efbfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
